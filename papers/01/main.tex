\documentclass[modern]{aastex631}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}

% page and document setup
\renewcommand{\twocolumngrid}{}
\addtolength{\topmargin}{-0.35in}
\addtolength{\textheight}{0.6in}
\setlength{\parindent}{3.5ex}
\renewcommand{\paragraph}[1]{\medskip\par\noindent\textbf{#1}~---}

% figure setup
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage[framemethod=tikz]{mdframed}
\usetikzlibrary{shadows}
\definecolor{captiongray}{HTML}{555555}
\mdfsetup{%
  innertopmargin=2ex,
  innerbottommargin=1.8ex,
  linecolor=captiongray,
  linewidth=0.5pt,
  roundcorner=1pt,
  shadow=false,
}
\newlength{\figurewidth}
\setlength{\figurewidth}{0.75\textwidth}

% text macros
\shorttitle{Astra}
\shortauthors{Casey et al.}
\newcommand{\documentname}{\textsl{Article}}
\newcommand{\sectionname}{Section}
\newcommand{\astra}{\texttt{Astra}}
\newcommand{\Astra}{\astra}
\newcommand{\pipeline}[1]{\texttt{#1}}

\newcommand{\APOGEENet}{\pipeline{APOGEENet}}
\newcommand{\BOSSNet}{\pipeline{BOSSNet}}

\newcommand{\pytorch}{PyTorch}


% math macros
\newcommand{\todo}[1]{\textcolor{orange}{#1}}
\newcommand{\unit}[1]{\mathrm{#1}}
\newcommand{\mps}{\unit{m\,s^{-1}}}
\newcommand{\kmps}{\unit{km\,s^{-1}}}

\newcommand{\teff}{T_\mathrm{eff}}
\newcommand{\logg}{\log_{10}(g)}
\newcommand{\mh}{[\mathrm{M/H}]}


\sloppy\sloppypar\raggedbottom\frenchspacing
\begin{document}

\title{\Huge Astra}

\author[0000-0003-0174-0564]{Andrew R. Casey}
\affiliation{School of Physics \& Astronomy, Monash University}
\affiliation{Centre of Excellence for Astrophysics in Three Dimensions (ASTRO-3D)}

\author{others}

\begin{abstract}

\end{abstract}

\keywords{Foo --- Bar}

\section*{}\clearpage
\section{Introduction}\label{sec:intro}
- In SDSS-V we are using the APOGEE instrument (infrared high res) and the BOSS instrument to observe N many stars as part of MWM
- In SDSS-V we are observing a wider range of stellar types than what was observed in SDSS-IV. Not just giants.
- The typical pipeline that would be suitable for FGKM stars is not suitable for things like white dwarfs.
- This means we end up needing to have multiple pipelines to analyse stars, at least those of different types.
- But since we will have more than one pipeline, we have taken a more elaborate approach to have multiple pipelines for all kinds of stars.
- The reasons for this are:
    - Stellar surveys tend to show substantial systematics with respect to each other
    - 'Allowing room' for multiple different pipelines is intended to encourage the development of new methods.
- This document describes the approach taken for the analysis of stellar parameters in SDSS-V.

\section{Methods}\label{sec:method}


\subsection{Design}

- What does \Astra need to do, other than just to run a loop over all the data?
- Needs to look for new reduced data products (either via on disk, or through a database).
- With each new data product, it records a database entry of that spectrum, so that every spectrum has a unique referenced spectrum index in the database.
- It needs to link that spectrum to an astronomical source. How this is achieved has varied over time, but has since stabilised with the introduction of SDSS ID.
- If we do not already have ancillary metadata for that object, then it needs to find and ingest that data. The ancillary data includes:
    - astrometry;
    - photometry;
    - targeting information;
    - identifiers to other catalogs, etc.
- If this spectrum is a combined spectrum from multiple visits or exposures, then Astra needs to go and find those visits and ingest those spectra. It needs to link those spectra to this combined spectrum.
- Needs to include relevant information from the data reduction pipeline, and any upstream information (e.g., radial velocities)

Why does it need to do all this? 
Because there will be multiple versions of the reduction for the data, and we want to be able to analyse all of those spectra and keep the results together in a database. Every spectrum in the database needs to be able to find the location of the spectrum on disk.

In the end, the output files that \astra\ prepares for a data release will be database exports of subsets of the data (e.g., for a specific data reduction version, range of observation dates, and telescope). 

\subsection{Self-documenting data files}
foo

\subsection{Pipelines}
Here we include a short description of all pipelines included in \astra. 
In general we reference the original papers of those pipelines for detailed explanations, however, we do list any modifications made to those pipelines.
All pipelines have been modified to some degree. In some cases only basic refactoring took place to make the functions compatible with how other pipelines are executed. Some pipelines perform some kind of functionality which we refactored because \astra\ includes that functionality as a common tool, and by refactoring the pipeline we were able to make easy tests of different choices (e.g., how continuum is modelled). In the most extreme cases, the pipeline has been re-written in it's entirety from scratch, whilst keeping the same approach.

\subsection{FERRE} \label{sec:methods-ferre}

FERRE \citep[or FERRE]{ferre} % \todo with the reverse R
is a FORTRAN tool to compare model spectra with observations.
The model spectra should be some rectilinear (evenly spaced) grid of spectra which you want to compare against models.
In the typical use case in \astra, the model grid is convolved to the expected spectral resolution and wavelength sampling of the data.
For a given observed spectrum, the best-fit model is found by interpolating a multi-dimensional grid of spectra.
For computational reasons, and to avoid the so-called `noding' effects \citep{CITE}, the grid of model spectra is stored in a compressed form.

FERRE includes some options when fitting spectra, including the initial guess, and any dimensions to be frozen. For more details see \citet{CITE}.
The continuum is optionally fit simultaneously with the stellar parameters, or can be performed before executing FERRE.
The best-fitting spectrum is found by an optimization routine (Nelder-Mead?).

%Only minimal changes were made to the FERRE code, but more substantive changes were made to the inputs that went in to FERRE (e.g., how ASPCAP is executed).
%Only minimal changes were made to the FERRE code, but more substantive changes were made to how FERRE was executed (e.g., see Section \ref{sec:aspcap-methods}).
The only changes made to FERRE were on the formats of output files. We added the \todo{input name} to output files to ensure that we could correctly order the results from all files when FERRE was being executed in parallel. 
Previously FERRE would correctly sort all files at the end of execution, but this sorting implementation was unexpectedly inefficient. 
After adding the FERRE input name to each row of the output files and the standard output, we disabled the concluding sorts.
Adding the input name to the standard output also allowed \astra\ to better track the time spent analysing per spectrum, and the joint overheads.

FERRE can be executed as a single task in \astra, but it is more often executed as just one step in the analysis.
Custom reader and writer functions to execute FERRE were added to \astra\ to handle the three ways in which FERRE is usually executed: for a coarse estimate of stellar parameters; a detailed fit of all stellar parameters; or by estimating the abundances. These populate different database tables. 

\subsection{ASPCAP} \label{sec:methods-aspcap}

ASPCAP is the APOGEE Stellar Parameter and Chemical Abundances Pipeline \citep{aspcap} that was developed and used by the APOGEE survey in SDSS-IV.\footnote{Those unfamiliar to SDSS may appreciate knowing that there is an APOGEE instrument \emph{and} an APOGEE survey. If not explicitly specified, when referring to APOGEE we mean the APOGEE instrument.}


The ASPCAP and FERRE codes are often described as being synonymous, but there is a clear delineation between the two. FERRE \citep[and Section \ref{sec:methods-ferre}][]{ferre} performs $\chi^2$ minimisation between an observed spectrum and some model grid. FERRE is not usually used to simultaneously estimate both the stellar parameters and detailed chemical abundances. ASPCAP refers to the procedure to estimate stellar parameters and chemical abundances of a star by calling FERRE multiple times.

In the context of SDSS, only APOGEE spectra are analysed with ASPCAP, but ASPCAP has been used for other surveys \citep{who}. 


ASPCAP is probably the most comprehensive pipeline that is integrated in \Astra, and has gone through the most refactoring. Here we will provide a slightly longer-than-average description of ASPCAP so that we can highlight differences in the ASPCAP version in \Astra.

The most notable difference in the ASPCAP implementation in \Astra\ is that it has been entirely re-written in Python. The ASPCAP implementation used in SDSS-IV was written in IDL. While \Astra\ could have executed the existing IDL pipeline, there were numerous technical reasons that motivated a rewrite. Institutional memory of the existing IDL pipeline was limited, and the existing implementation planned executions on a per-plate basis -- a concept which was to change with the new fiber positioners in SDSS-V. Some re-structering of the code would be required to handle changes in file paths, data models, etc. Having a Python based version also gave more flexibility to experiment and improve the code. 


ASPCAP executes FERRE many times using different grids, where each grid might cover some subset of stellar parameter space. The hot star grid is convolved to a representative spectral resolution of 22,500, but the other grids are convolved with four different line spread functions. The fiber used to observe the target (or the mean fiber from multiple observations) determines which of the four convolved grids will be used.

There are three sequential stages in ASPCAP: 
  the coarse stage, 
  the stellar parameter stage, and 
  the chemical abundances stage. 
At the start of the coarse stage, it is useful if there is an initial guess of the stellar parameters for soem given spectrum. In SDSS-IV, the Doppler estimate of the stellar parameters was often used as the initial guess. In SDSS-V we use the stellar parameters from \APOGEENet\ if available (for that spectrum, or alternatively for that star), and revert to the Doppler estimate if there are no \APOGEENet\ results available. A bitmask flag is recorded to indicate the source of the initial guess.

Given the initial guess, we consider whether each grid spans that position in stellar parameters. If it does-- and if the LSF matches that for the fiber, or it is the hot star grid -- then that grid will be used to estimate coarse stellar parameters for the given spectrum. Because the grids used will overlap in stellar parameters \citep{dr17-grids}, it is frequent that the same spectrum will be analysed twice during the coarse stellar parameter stage. 

In the special case where no initial guess is available, \emph{all} grids with a suitable LSF will be used in the coarse parameter stage. 


Multiple dimensions of the FERRE grid are held fixed during the coarse stellar parameter stage. For main-sequence grids, we \todo{fix [C/M], [N/M], [$\alpha$/M] = 0}. \todo{Microturbulence is also kept fixed based on the following relation.}. For giant star grids, we fix \todo{X, Y, and Z}.

When multiple FERRE executions have taken place for a single spectrum in the coarse stage, the best set of coarse stellar parameters is found by comparing the (penalized) $\chi^2$ of different solutions. The penalized value takes the original $\chi^2$ value and multiplies it if specific conditions are met. For example, if the effective temperature or surface gravity is within the last node of a grid edge, it is multiplied by 5. If those parameters are within 1/8th of the edge grid spacing, it is multiplied by 10. If FERRE fails to report an effecive temperature or surface gravity, it is multiplied by 20. The final condition is for stars with FERRE-reported $\teff < 3900$\,K and if the GK-type grid was used. In that condition, the $\chi^2$ is penalized by 10. 


%The results from each FERRE execution are stored in the \Astra\ database, but these are not usually acces

\subsubsection{Stellar Parameters Stage}

All stellar parameters are allowed to vary in this stage. The best result from the coarse stage is used as an initial guess in the stellar parameter stage, and the FERRE grid where that coarse stage was reported is taken as the grid to use in the stellar parameter stage. 

Like in SDSS-IV, a pseudo-continuum normalisation is performed before the stellar parameter stage. We take the best-fitting result from the coarse stage and divide the model spectrum by the observed one on a per-chip basis. We interpolate over bad pixels (e.g., extremely low, high, or non-finite flux) and compute a median filter of the `ratio spectrum' with a filter width of 151 pixels. This matches the approach used in SDSS-IV, but the implementation can lead to slightly different results. The median filter of the ratio spectrum is then assumed to be the continuum for the stellar parameters stage. 

The biggest source of differences in stellar parameters between the ASPCAP implementation used in SDSS-IV, and the Python version implemented in \Astra, likely arise from different choices of initial guesses (e.g., using \APOGEENet\ instead of Doppler) and minor adjustments to how the median filter is applied for the pre-continuum step.

\subsubsection{Chemical abundances stage}


In the chemical abundances stage of ASPCAP the stellar parameters are held fixed to the values found in the earlier stage, and the abundances are determined by allowing metallicity-sensitive dimension to vary. The technical details about how this is done is the same as in SDSS-IV (e.g., through \texttt{TTIES} keywords and freezing parameters). 

In SDSS-IV the median filtering procedure is also applied before the chemical abundances stage (using the best-fitting result from the stellar parameter stage). The \Astra\ implementation does the same thing, but it does not allow FERRE to adjust the continuum during the chemical abundances stage. The logic is that some chemical abundances are only inferred from a very small number of pixels, and if we also allow a fourth order polynomial to vary while trying to fit a chemical abundance to a few pixels, the problem will be too degenerate. For this reason, the ASPCAP version in \Astra\ will perform the pre-continuum step before the chemical abundances stage, but it will then disable any continuum-fitting options in FERRE. 


\subsubsection{ASCPAP results}

A single spectrum analysed by ASPCAP might involve 30 or more FERRE executions: a few in the coarse stage, one in the stellar parameter stage, and the remainder during the chemical abundances stage.

The results from each FERRE execution are available in the \Astra\ database, but are not usually made available to users through output tables. Most users want the stellar parameters estimated during the stellar parameter stage, and a summary of abundances from the executions made during the chemical abundances stage.

For these reasons, a final task queries the results from the different FERRE tables and creates a usable table of stellar parameters and chemical abundances, with primary keys linking to the individual tasks. 

\todo{Corrections made. What elements do we incldue this time round?}


\subsection{The Payne} \label{sec:methods-the-payne}

\subsection{The Cannon} \label{sec:methods-the-cannon}

The Cannon \citep{Ness,thecannon} is a data-driven method for estimating stellar labels ($\teff$, $\logg$, chemical abundances,and more). The implementation of The Cannon in \Astra\ is suitable for use with either APOGEE or BOSS spectra. Since all the spectra in the \Astra\ database are linked to other survey identifiers, one can easily train a new model with The Cannon that uses published labels from a previous SDSS data release. 

The Cannon implementation in \Astra\ is trained by using the coordinate descent algorithm, which differs from how previous implementations were optimised. Coordinate descent seems to be efficient for small or large models, and the CPU cost to train a model does not vary substantially with increasing regularisation. In practice, previous implementations seemed to have a higher CPU cost as the regularisation strength grew. Coordinate descent also seems to produce sparser models with more interpretable flux derivatives.

\todo{Fixing s2 after the fact}

Since highly regularised models can be trained efficiently via coordinate descent, the new implementation of The Cannon in \astra\ allows for grid searches in the regularization strength $\lambda$. The default grid search behaviour is to place uniform-in-log values of $\Lambda$ between $10^{-8}$ and $10^{-1}$, and train a model at each regularization strength. We then compute the $\chi^2$ of the validation set (distinct from the training set) by predicting the spectra of the validation set -- with the validation labels -- and computing the $\chi^2$ difference. Like \citet{Casey} and elsewhere, we find there is a minima where an increasing regularization strength produces a sparser model that also makes better predictions of spectra. We take the minima of this to be the regularization strength. 



\subsection{The Classifier} \label{sec:methods-the-classifier}


\subsection{Snow White} \label{sec:methods-snow-white}

The `Snow White' pipeline exclusively analyses white dwarf spectra, which are usually observed with the BOSS 
spectrograph. % todo: how many white dwarfs observed with BOSS compared to APOGEE or both?
`Snow White' measures the equivalent width of \todo{N} lines, and uses a pre-trained random forest \citep{RF} to classify white dwarfs into their sub-types. For white dwarfs that are classified as primarily DA-type, the stellar parameters are fit by interpolating a grid of \citep{who} model spectra and minimising the $\chi^2$ difference between the model and data.

% todos here
- what model grid is used?
- which lines are used?
- continuum normalisation?
- linear interpolation? in how many dimensions
- PCA compression?
- what are the different classification methods and meanings? (there is some structure to this based on the types and probabilistic classifications)

\subsection{MDwarfType} \label{sec:methods-m-dwarf-type}

The `MDwarfType' pipeline classifies M-dwarfs based on an empirical library of \todo{N} spectra of late K- and M-type stars. The empirical library was constructed by Lepine et al. from observations taken at \todo{where}. The \todo{N} spectra have been continuum-rectified by taking the \todo{mean flux between X and Y}.

Most M-dwarf stars in Milky Way Mapper are observed by BOSS (\todo{percent}). We normalise the BOSS observations in the same way that the empirical library has been normalised. We compute the $\chi^2$ difference between the observed spectrum and all \todo{N} templates, and report the best-fitting $\chi^2$ value and template type. The template type includes the spectral classification, as well as a so-called `sub-type' which is used as a coarse proxy for an M-dwarf metallicity.

The `MDwarfType` pipeline is only executed on main-sequence type stars that have been assigned to a carton that is studying M-dwarf stars. That list includes \todo{here}. \todo{Any additional photometric cut that we put on these?}.

% todo citation literature for all the Lepine group stuff.

% todo: a figure of the empirical spectra?

\subsection{HotPayne} \label{sec:methods-hot-payne}

\subsection{APOGEENet} \label{sec:methods-apogee-net}

\todo{We have versions 2 and 3 in astra}

\APOGEENet\ is a convolutional neural network for estimating stellar parameters ($\teff$, $\logg$, $\mh$) from APOGEE spectra \citep{apogeenet}. Previous versions of \APOGEENet\ required infrared photometry and astrometry (e.g., parallax to compute absolute magnitudes), and in those versions the results were sensitive to missing data. The current version of \APOGEENet\ is version 3, which does not require auxillary photometry. 

\APOGEENet\ is trained on high quality labels from SDSS-IV DR17 \citep{dr17}. 

It is implemented in \pytorch\ and is most efficiently executed on a graphics processing unit (GPU). \Astra\ can readily orchestrate tasks across CPU or GPU clusters, and the default is for \APOGEENet\ to be executed on shared GPU infrastructure at Utah.

\todo{- network structure}

Only minor technical changes were made to the \APOGEENet\ pipeline in \Astra. A task function was written to execute spectra, and we added a load balancer to better handle CPU/GPU bottlenecks.

\subsection{BOSSNet} \label{sec:methods-boss-net}

\BOSSNet\ is a convolutional neural network for estimating stellar parameters ($\teff$, $\logg$, $\mh$) from BOSS spectra \citep{bossnet}. \BOSSNet\ is the natural extension to optical spectra from the same group that developed \APOGEENet. Like the current version of \APOGEENet, no auxillary photometry or astrometry is required by \BOSSNet.

\todo{
- network structure
- training set for bossnet
- testing set
}

\subsection{AstroNN} \label{sec:methods-astro-nn}

\subsection{CORV}

The COmpact Radial Velocity (\texttt{corv}) code computes radial velocities for compact objects. Presently it only computes radial velocities for sources that the \texttt{SnowWhite} pipeline has classified as a DA-type white dwarf, and \texttt{SnowWhite} is only executed on sources that were assigned to a white dwarf carton (\todo{name them}).

CORV fits the hydrogen lines of DA-type white dwarfs either by linearly interpolating spectra from an existing grid, or by directly fitting voigt profiles to the hydrogen lines. In data release 19, the \todo{voigt profile results} are used. The reported results include radial velocity (and associated error), effective temperature, surface gravity, and other metadata. No substantive changes were made to this code; the minimal amount of refactoring necessary was done.

\subsection{LineForest} \label{sec:methods-line-forest}

\LineForest\ measures the integrated strength of up to 52 strong transitions in the BOSS wavelength region. \LineForest\ is executed on the per-MJD BOSS visits, and on the combined BOSS spectrum of anything that looks like a star (see Targeting section). A complete description of \LineForest\ can be foudn in \citet{somewhere}. The transitions include hydrogen line (Balmer H1-17, Paschen 7-17), strong calcium lines (Ca H, K, Ca II triplet), He I and II lines, as well as N, S, Fe, O, and Li. A pre-set window is used around each line to determine the strength of the line relative to the local continuum (usually 50 or 200\,\AA). The equivalent width of each transition is reported, as well as metrics related to the detection significance, and percentiles of the equivalent width. 


\subsection{SLAM} \label{sec:methods-slam}

The Stellar Labels Machine (SLAM) is a \todo{...}.

It only considers spectra between 6417 and 8910\,\AA. 

Using a model trained on ASPCAP labels from DR16.

The Slam performs an initial normalization of the BOSS spectrum and re-samples it to the wavelength of the model grid using a cubic spline. An initial estimate of the stellar parameters is then found by a $\chi^2$ match to the grid, which is then refined by optimizing the stellar parameters. This version of the Slam is trained on ASPCAP labels from DR16, and only $\teff$ and $\mh$ are reported (with their associated uncertainties and covariances).


In \todo{IPL-3}, the Slam was executed on any source that was assigned to either the solar neighbourhood census carton (\texttt{mwm\_snc}) or the young stellar object carton (\texttt{mwm\_yso}), or if it met the following criteria:
\begin{itemize}
	\item has a reported G-band magnitude from Gaia DR3;
	\item has a reported RP-band magnitude from Gaia DR3;
	\item has a non-negative parallax in Gaia DR3;
	\item has $(G - RP) > 0.56$; and
	\item has an absolute G-band magnitude greater than 5.553
\end{itemize}


\subsection{
\section{Results}\label{sec:results}

- Refer to Don Schneider stuff

- Comments on individual pipeline results? I guess just flagging st


\section{Discussion} \label{sec:discussion}


\section{Conclusions}

\paragraph{Software}
\texttt{numpy} \citep{numpy} ---
\texttt{matplotlib} \citep{matplotlib}.

\paragraph{Acknowledgements}
It is a pleasure to thank
-- people
for valuable discussions and input.

\begin{thebibliography}{dummy}
\bibitem[Kelson(2003)]{kelson} Kelson, D.~D.\ 2003, \pasp, 115, 688. doi:10.1086/375502
\end{thebibliography}

\end{document}
